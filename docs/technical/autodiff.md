\page technicalAutodiff Automatic Differentiation (Autodiff)
\tableofcontents

Optimization in the context of deep learning often means finding a local minimum of the loss function via some form of
gradient descent. As such, the support for automatic differentiation (autodiff), i.e., computing the gradient without
manually calculating the derivative, is central to any deep learning library that actually wants to support the
"learning" part.


# How it works
\todo WIP


# Adding Autodiff Support to a Function
\todo WIP


# Gradients
## Gradients of Matrix Operations
### Matrix Product
\todo WIP