<!-- Heavily based on https://github.com/jothepro/doxygen-awesome-css/blob/main/doxygen-custom/header.html -->
<!DOCTYPE html
    PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=9" />
    <meta name="generator" content="Doxygen 1.9.8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <!-- BEGIN opengraph metadata -->
    <meta property="og:title" content=libdl />
    <meta property="og:image" content="twemoji-brain.png" />
    <meta property="og:description" content="Simple yet powerful deep learning" />
    <meta property="og:url" content="https://github.com/TheMrSheldon/libdl" />
    <!-- END opengraph metadata -->
    <!-- BEGIN twitter metadata -->
    <meta name="twitter:image:src" content="twemoji-brain.png" />
    <meta name="twitter:title" content="libdl" />
    <meta name="twitter:description" content="Simple yet powerful deep learning" />
    <!-- END twitter metadata -->
    <title>libdl: dl::TransformerEncoder Class Reference</title>
    <link href="tabs.css" rel="stylesheet" type="text/css" />
    <link rel="icon" type="image/svg+xml" href="twemoji-brain.png" />
    <script type="text/javascript" src="jquery.js"></script>
    <script type="text/javascript" src="dynsections.js"></script>
    <script type="text/javascript" src="doxygen-awesome-darkmode-toggle.js"></script>
    <script type="text/javascript" src="doxygen-awesome-fragment-copy-button.js"></script>
    <script type="text/javascript" src="doxygen-awesome-paragraph-link.js"></script>
    <script type="text/javascript" src="doxygen-awesome-interactive-toc.js"></script>
    <script type="text/javascript" src="doxygen-awesome-tabs.js"></script>
    <script type="text/javascript" src="toggle-alternative-theme.js"></script>
    <script type="text/javascript">
        DoxygenAwesomeFragmentCopyButton.init()
        DoxygenAwesomeDarkModeToggle.init()
        DoxygenAwesomeParagraphLink.init()
        DoxygenAwesomeInteractiveToc.init()
        DoxygenAwesomeTabs.init()
    </script>
    <link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
    <link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js"></script>
    <link href="doxygen.css" rel="stylesheet" type="text/css" />
    <link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only-darkmode-toggle.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-tabs.js" rel="stylesheet" type="text/css"/>
<link href="custom.css" rel="stylesheet" type="text/css"/>
</head>
<body>
    <!-- https://tholman.com/github-corners/ -->
    <a href="https://github.com/TheMrSheldon/libdl" class="github-corner" title="View source on GitHub" target="_blank"
        rel="noopener noreferrer">
        <svg viewBox="0 0 250 250" width="40" height="40"
            style="position: absolute; top: 0; border: 0; right: 0; z-index: 99;" aria-hidden="true">
            <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
            <path
                d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
                fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
            <path
                d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
                fill="currentColor" class="octo-body"></path>
        </svg></a>
    <style>
        .github-corner:hover .octo-arm {
            animation: octocat-wave 560ms ease-in-out
        }
        @keyframes octocat-wave {
            0%,
            100% {
                transform: rotate(0)
            }
            20%,
            60% {
                transform: rotate(-25deg)
            }
            40%,
            80% {
                transform: rotate(10deg)
            }
        }
        @media (max-width:500px) {
            .github-corner:hover .octo-arm {
                animation: none
            }
            .github-corner .octo-arm {
                animation: octocat-wave 560ms ease-in-out
            }
        }
    </style>
    <div id="top"><!-- do not remove this div, it is closed by doxygen! -->
        <div id="titlearea">
            <table cellspacing="0" cellpadding="0">
                <tbody>
                    <tr style="height: 56px;">
                        <td id="projectlogo"><img alt="Logo" src="twemoji-brain.png" /></td>
                        <td id="projectalign" style="padding-left: 0.5em;">
                            <div id="projectname">libdl
                                &#160;<span
                                    id="projectnumber">0.0.1</span>
                            </div>
                            <div id="projectbrief">Simple yet powerful deep learning</div>
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
        <!-- end header part --><!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classdl_1_1TransformerEncoder.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="classdl_1_1TransformerEncoder-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">dl::TransformerEncoder Class Reference<span class="mlabels"><span class="mlabel">final</span></span></div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for dl::TransformerEncoder:</div>
<div class="dyncontent">
<div class="center"><img src="classdl_1_1TransformerEncoder__inherit__graph.png" border="0" usemap="#adl_1_1TransformerEncoder_inherit__map" alt="Inheritance graph"/></div>
<map name="adl_1_1TransformerEncoder_inherit__map" id="adl_1_1TransformerEncoder_inherit__map">
<area shape="rect" title=" " alt="" coords="27,79,199,104"/>
<area shape="rect" href="classdl_1_1Model.html" title=" " alt="" coords="5,5,221,31"/>
<area shape="poly" title=" " alt="" coords="116,44,116,79,111,79,111,44"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for dl::TransformerEncoder:</div>
<div class="dyncontent">
<div class="center"><img src="classdl_1_1TransformerEncoder__coll__graph.png" border="0" usemap="#adl_1_1TransformerEncoder_coll__map" alt="Collaboration graph"/></div>
<map name="adl_1_1TransformerEncoder_coll__map" id="adl_1_1TransformerEncoder_coll__map">
<area shape="rect" title=" " alt="" coords="27,79,199,104"/>
<area shape="rect" href="classdl_1_1Model.html" title=" " alt="" coords="5,5,221,31"/>
<area shape="poly" title=" " alt="" coords="116,44,116,79,111,79,111,44"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ab43743e37433f50957499e8fa18be9c6" id="r_ab43743e37433f50957499e8fa18be9c6"><td class="memItemLeft" align="right" valign="top"><a id="ab43743e37433f50957499e8fa18be9c6" name="ab43743e37433f50957499e8fa18be9c6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>TransformerEncoder</b> (<a class="el" href="structdl_1_1TransformerConf.html">TransformerConf</a> conf) noexcept</td></tr>
<tr class="separator:ab43743e37433f50957499e8fa18be9c6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adb23b94e091ff50ddb6f9e68bd709e62" id="r_adb23b94e091ff50ddb6f9e68bd709e62"><td class="memItemLeft" align="right" valign="top"><a id="adb23b94e091ff50ddb6f9e68bd709e62" name="adb23b94e091ff50ddb6f9e68bd709e62"></a>
virtual <a class="el" href="classdl_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><b>forward</b> (<a class="el" href="classdl_1_1Tensor.html">Tensor</a> &amp;input) override</td></tr>
<tr class="separator:adb23b94e091ff50ddb6f9e68bd709e62"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a717deaf44d6c7970d4e5f71650775eef" id="r_a717deaf44d6c7970d4e5f71650775eef"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classdl_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classdl_1_1TransformerEncoder.html#a717deaf44d6c7970d4e5f71650775eef">scaledDotProductAttention</a> (<a class="el" href="classdl_1_1Tensor.html">Tensor</a> &amp;&amp;query, <a class="el" href="classdl_1_1Tensor.html">Tensor</a> &amp;&amp;key, <a class="el" href="classdl_1_1Tensor.html">Tensor</a> &amp;&amp;value) noexcept</td></tr>
<tr class="memdesc:a717deaf44d6c7970d4e5f71650775eef"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implements the scaled dot-product attention.  <br /></td></tr>
<tr class="separator:a717deaf44d6c7970d4e5f71650775eef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d259db4340981b8ae6a3c9a3ef89948" id="r_a7d259db4340981b8ae6a3c9a3ef89948"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classdl_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classdl_1_1TransformerEncoder.html#a7d259db4340981b8ae6a3c9a3ef89948">multiHeadAttention</a> (<a class="el" href="classdl_1_1Tensor.html">Tensor</a> &amp;&amp;query, <a class="el" href="classdl_1_1Tensor.html">Tensor</a> &amp;&amp;key, <a class="el" href="classdl_1_1Tensor.html">Tensor</a> &amp;&amp;value) noexcept</td></tr>
<tr class="memdesc:a7d259db4340981b8ae6a3c9a3ef89948"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implements the transformer's multi-head attention.  <br /></td></tr>
<tr class="separator:a7d259db4340981b8ae6a3c9a3ef89948"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a3240e4e21fa78b7e31dfe71aefef396d" id="r_a3240e4e21fa78b7e31dfe71aefef396d"><td class="memItemLeft" align="right" valign="top">const double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classdl_1_1TransformerEncoder.html#a3240e4e21fa78b7e31dfe71aefef396d">dimKeysInvSqrt</a></td></tr>
<tr class="memdesc:a3240e4e21fa78b7e31dfe71aefef396d"><td class="mdescLeft">&#160;</td><td class="mdescRight">The precomputed inverse square root of dimKeys.  <br /></td></tr>
<tr class="separator:a3240e4e21fa78b7e31dfe71aefef396d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock">
<p class="definition">Definition at line <a class="el" href="transformer_8hpp_source.html#l00036">36</a> of file <a class="el" href="transformer_8hpp_source.html">transformer.hpp</a>.</p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a7d259db4340981b8ae6a3c9a3ef89948" name="a7d259db4340981b8ae6a3c9a3ef89948"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d259db4340981b8ae6a3c9a3ef89948">&#9670;&#160;</a></span>multiHeadAttention()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classdl_1_1Tensor.html">Tensor</a> dl::TransformerEncoder::multiHeadAttention </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classdl_1_1Tensor.html">Tensor</a> &amp;&amp;&#160;</td>
          <td class="paramname"><em>query</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classdl_1_1Tensor.html">Tensor</a> &amp;&amp;&#160;</td>
          <td class="paramname"><em>key</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classdl_1_1Tensor.html">Tensor</a> &amp;&amp;&#160;</td>
          <td class="paramname"><em>value</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Implements the transformer's multi-head attention. </p>
<p>Multi-head attention is chapter 3.2.2 in the transformer paper <a class="el" href="citelist.html#CITEREF_transformer">[4]</a>. Let \(W_i^Q, W_i^K\in \mathbb{R}^{d_\text{model} \times d_k}, W_i^V \in \mathbb{R}^{d_\text{model} \times d_v}\) denote the query, key and value matrix of the i-th head respectively for \(1\leq i \leq h\), where \(h\) is the total number of heads. Further, let \(W^O\) denote the output linearity. Multi-head attention is defined as the concatinated attention of each attention head:  </p><p class="formulaDsp">
\[
    \text{MHA}(Q, K, V) = \text{Concat}(\text{head}_1, \dots, \text{head}_h)\cdot W^O \text{ with }
    \text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V),
\]
</p>
<p> where "Attention" denotes scaledDotProductAttention (<a class="el" href="classdl_1_1TransformerEncoder.html#a717deaf44d6c7970d4e5f71650775eef" title="Implements the scaled dot-product attention.">TransformerEncoder::scaledDotProductAttention</a>).</p>
<dl class="section note"><dt>Note</dt><dd>In practice, the linearities are usually accompanied with biases \(b^O, b_i^Q, b_i^K, b_i^V \in \mathbb{R}^{d_\text{model}}\), such that MHA is more accurately described as  <p class="formulaDsp">
\[\text{MHA}(Q, K, V) = \text{Concat}(
        \text{Attention}(QW_1^Q+b_1^Q, KW_1^K+b_1^K, VW_1^V+b_1^V), \dots)\cdot W^O + b^O.\]
</p>
</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">query</td><td></td></tr>
    <tr><td class="paramname">key</td><td></td></tr>
    <tr><td class="paramname">value</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="classdl_1_1Tensor.html" title="The Tensor is a managed pointer to a tensor. It can generally be thought of like an std::unique_ptr&lt;T...">Tensor</a> </dd></dl>
<dl class="section see"><dt>See also</dt><dd>For a more detailed description, please read the technicalTransformer page. </dd></dl>

</div>
</div>
<a id="a717deaf44d6c7970d4e5f71650775eef" name="a717deaf44d6c7970d4e5f71650775eef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a717deaf44d6c7970d4e5f71650775eef">&#9670;&#160;</a></span>scaledDotProductAttention()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classdl_1_1Tensor.html">Tensor</a> dl::TransformerEncoder::scaledDotProductAttention </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classdl_1_1Tensor.html">Tensor</a> &amp;&amp;&#160;</td>
          <td class="paramname"><em>query</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classdl_1_1Tensor.html">Tensor</a> &amp;&amp;&#160;</td>
          <td class="paramname"><em>key</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classdl_1_1Tensor.html">Tensor</a> &amp;&amp;&#160;</td>
          <td class="paramname"><em>value</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Implements the scaled dot-product attention. </p>
<p>Scaled dot-product attention is Eq. (1) in the transformer paper <a class="el" href="citelist.html#CITEREF_transformer">[4]</a> : </p><p class="formulaDsp">
\[\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^\top}{\sqrt{d_k}}\right)V.\]
</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td></td></tr>
    <tr><td class="paramname">key</td><td></td></tr>
    <tr><td class="paramname">query</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>the scaled dot-product attention. </dd></dl>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a3240e4e21fa78b7e31dfe71aefef396d" name="a3240e4e21fa78b7e31dfe71aefef396d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3240e4e21fa78b7e31dfe71aefef396d">&#9670;&#160;</a></span>dimKeysInvSqrt</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double dl::TransformerEncoder::dimKeysInvSqrt</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The precomputed inverse square root of dimKeys. </p>
<p>This is the precomputed normalization factor \(\sqrt{d_k}^{-1}\) used in the scaled dot-product attention. </p>

<p class="definition">Definition at line <a class="el" href="transformer_8hpp_source.html#l00062">62</a> of file <a class="el" href="transformer_8hpp_source.html">transformer.hpp</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>dl/model/transformer/<a class="el" href="transformer_8hpp_source.html">transformer.hpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><b>dl</b></li><li class="navelem"><a class="el" href="classdl_1_1TransformerEncoder.html">TransformerEncoder</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
